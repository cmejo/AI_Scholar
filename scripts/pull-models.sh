#!/bin/bash

# Script to pull Ollama models for AI Scholar
echo "ðŸš€ Pulling Ollama models for AI Scholar..."

# Set Ollama host
export OLLAMA_HOST=http://localhost:11435

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
while ! curl -s http://localhost:11435/api/tags > /dev/null; do
    echo "Waiting for Ollama service..."
    sleep 5
done

echo "âœ… Ollama is ready!"

# Pull models
echo "ðŸ“¥ Pulling llama3.1:8b (default model)..."
ollama pull llama3.1:8b

echo "ðŸ“¥ Pulling llama3.1:70b (large model)..."
ollama pull llama3.1:70b

echo "ðŸ“¥ Pulling qwen2:72b (reasoning model)..."
ollama pull qwen2:72b

echo "ðŸ“¥ Pulling codellama:34b (code model)..."
ollama pull codellama:34b

echo "ðŸŽ‰ All models pulled successfully!"

# List available models
echo "ðŸ“‹ Available models:"
ollama list