#!/usr/bin/env python3
"""
Task 6.3 Verification: Build research insights and gap analysis
Tests the complete implementation of topic clustering, theme identification,
research gap detection, and trend analysis with research direction suggestions.
"""

import asyncio
import json
import sys
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any
from unittest.mock import Mock, patch

# Add the backend directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

from services.zotero.zotero_research_insights_service import ZoteroResearchInsightsService
from models.zotero_models import ZoteroItem, ZoteroLibrary, ZoteroConnection


class TestZoteroResearchInsightsTask63:
    """Test Task 6.3: Research insights and gap analysis implementation"""
    
    def __init__(self):
        self.service = ZoteroResearchInsightsService()
        self.test_results = {
            "task_6_3_tests": {
                "topic_clustering": {"status": "pending", "details": {}},
                "theme_identification": {"status": "pending", "details": {}},
                "gap_detection": {"status": "pending", "details": {}},
                "trend_analysis": {"status": "pending", "details": {}},
                "research_directions": {"status": "pending", "details": {}},
                "integration_tests": {"status": "pending", "details": {}}
            }
        }
    
    def create_comprehensive_test_data(self) -> List[ZoteroItem]:
        """Create comprehensive test data for research insights analysis"""
        items = []
        
        # Create diverse research items spanning multiple years and topics
        test_data = [
            {
                "title": "Machine Learning Applications in Healthcare Diagnosis",
                "year": 2023,
                "abstract": "This study explores the use of machine learning algorithms for medical diagnosis, focusing on deep learning approaches for image analysis and pattern recognition in clinical settings.",
                "topics": ["machine learning", "healthcare", "medical diagnosis", "deep learning"],
                "methodology": "experimental",
                "creators": [{"firstName": "Alice", "lastName": "Johnson", "creatorType": "author"}],
                "publication": "Journal of Medical Informatics"
            },
            {
                "title": "Deep Learning for Computer Vision in Autonomous Vehicles",
                "year": 2023,
                "abstract": "An investigation into deep learning techniques for real-time object detection and recognition in autonomous driving systems.",
                "topics": ["deep learning", "computer vision", "autonomous vehicles", "object detection"],
                "methodology": "experimental",
                "creators": [{"firstName": "Bob", "lastName": "Smith", "creatorType": "author"}, {"firstName": "Carol", "lastName": "Davis", "creatorType": "author"}],
                "publication": "IEEE Transactions on Intelligent Transportation"
            },
            {
                "title": "Natural Language Processing for Social Media Analysis",
                "year": 2022,
                "abstract": "This paper presents novel approaches to sentiment analysis and topic modeling for social media content using transformer-based models.",
                "topics": ["natural language processing", "social media", "sentiment analysis", "transformers"],
                "methodology": "experimental",
                "creators": [{"firstName": "David", "lastName": "Wilson", "creatorType": "author"}],
                "publication": "Computational Linguistics Journal"
            },
            {
                "title": "Blockchain Technology in Supply Chain Management",
                "year": 2022,
                "abstract": "A comprehensive study of blockchain applications for improving transparency and traceability in global supply chains.",
                "topics": ["blockchain", "supply chain", "transparency", "distributed systems"],
                "methodology": "case study",
                "creators": [{"firstName": "Eve", "lastName": "Brown", "creatorType": "author"}, {"firstName": "Frank", "lastName": "Miller", "creatorType": "author"}],
                "publication": "Supply Chain Management Review"
            },
            {
                "title": "Quantum Computing Algorithms for Optimization Problems",
                "year": 2021,
                "abstract": "This research investigates quantum algorithms for solving complex optimization problems, with applications in logistics and resource allocation.",
                "topics": ["quantum computing", "optimization", "algorithms", "quantum algorithms"],
                "methodology": "theoretical",
                "creators": [{"firstName": "Grace", "lastName": "Taylor", "creatorType": "author"}],
                "publication": "Quantum Information Processing"
            },
            {
                "title": "Cybersecurity Threats in IoT Networks",
                "year": 2021,
                "abstract": "An analysis of security vulnerabilities in Internet of Things networks and proposed mitigation strategies.",
                "topics": ["cybersecurity", "IoT", "network security", "vulnerability analysis"],
                "methodology": "survey",
                "creators": [{"firstName": "Henry", "lastName": "Anderson", "creatorType": "author"}, {"firstName": "Iris", "lastName": "Thomas", "creatorType": "author"}],
                "publication": "IEEE Security & Privacy"
            },
            {
                "title": "Sustainable Energy Systems and Smart Grids",
                "year": 2020,
                "abstract": "This study examines the integration of renewable energy sources with smart grid technologies for sustainable power distribution.",
                "topics": ["sustainable energy", "smart grids", "renewable energy", "power systems"],
                "methodology": "case study",
                "creators": [{"firstName": "Jack", "lastName": "Garcia", "creatorType": "author"}],
                "publication": "Energy Policy Journal"
            },
            {
                "title": "Augmented Reality in Education: A Systematic Review",
                "year": 2020,
                "abstract": "A comprehensive review of augmented reality applications in educational settings, analyzing effectiveness and implementation challenges.",
                "topics": ["augmented reality", "education", "learning technologies", "systematic review"],
                "methodology": "systematic review",
                "creators": [{"firstName": "Karen", "lastName": "Martinez", "creatorType": "author"}, {"firstName": "Leo", "lastName": "Rodriguez", "creatorType": "author"}],
                "publication": "Educational Technology Research"
            },
            {
                "title": "Artificial Intelligence Ethics and Bias Detection",
                "year": 2024,
                "abstract": "This paper addresses ethical considerations in AI systems and proposes methods for detecting and mitigating algorithmic bias.",
                "topics": ["artificial intelligence", "ethics", "bias detection", "fairness"],
                "methodology": "mixed methods",
                "creators": [{"firstName": "Maria", "lastName": "Lopez", "creatorType": "author"}],
                "publication": "AI Ethics Journal"
            },
            {
                "title": "Edge Computing for Real-time Data Processing",
                "year": 2024,
                "abstract": "An investigation into edge computing architectures for processing real-time data streams in distributed environments.",
                "topics": ["edge computing", "real-time processing", "distributed systems", "data streams"],
                "methodology": "experimental",
                "creators": [{"firstName": "Nina", "lastName": "Clark", "creatorType": "author"}, {"firstName": "Oscar", "lastName": "Lewis", "creatorType": "author"}],
                "publication": "IEEE Computer"
            }
        ]
        
        for i, data in enumerate(test_data):
            item = ZoteroItem(
                id=f"item_{i}",
                library_id="test_lib_123",
                zotero_item_key=f"TESTKEY{i}",
                item_type="journalArticle",
                title=data["title"],
                publication_year=data["year"],
                publication_title=data["publication"],
                abstract_note=data["abstract"],
                creators=data["creators"],
                tags=data["topics"],
                doi=f"10.1000/test.{i}",
                item_metadata={
                    "ai_analysis": {
                        "results": {
                            "topics": {
                                "primary_topics": data["topics"],
                                "methodology": data["methodology"],
                                "research_domain": "Computer Science" if any(t in data["topics"] for t in ["machine learning", "deep learning", "computer vision"]) else "Interdisciplinary"
                            }
                        }
                    }
                }
            )
            items.append(item)
        
        return items
    
    async def test_topic_clustering_and_theme_identification(self):
        """Test topic clustering and theme identification functionality"""
        print("Testing topic clustering and theme identification...")
        
        try:
            test_items = self.create_comprehensive_test_data()
            user_id = "test_user_123"
            
            with patch.object(self.service, '_get_user_items_for_analysis', return_value=test_items):
                # Test theme identification
                result = await self.service.identify_research_themes(
                    user_id=user_id,
                    clustering_method="kmeans",
                    num_themes=4
                )
                
                # Verify theme identification results
                assert "themes" in result
                assert len(result["themes"]) > 0
                assert result["clustering_method"] == "kmeans"
                assert result["user_id"] == user_id
                
                # Verify theme structure
                for theme in result["themes"]:
                    assert "theme_id" in theme
                    assert "theme_name" in theme
                    assert "keywords" in theme
                    assert "summary" in theme
                    assert "item_count" in theme
                    assert "items" in theme
                    assert "coherence_score" in theme
                    assert "insights" in theme
                    assert "research_directions" in theme
                
                self.test_results["task_6_3_tests"]["topic_clustering"]["status"] = "passed"
                self.test_results["task_6_3_tests"]["topic_clustering"]["details"] = {
                    "themes_identified": len(result["themes"]),
                    "clustering_method": result["clustering_method"],
                    "items_analyzed": result["total_items_analyzed"]
                }
                
                self.test_results["task_6_3_tests"]["theme_identification"]["status"] = "passed"
                self.test_results["task_6_3_tests"]["theme_identification"]["details"] = {
                    "themes_with_insights": len([t for t in result["themes"] if t.get("insights")]),
                    "themes_with_directions": len([t for t in result["themes"] if t.get("research_directions")]),
                    "average_coherence": sum(t.get("coherence_score", 0) for t in result["themes"]) / len(result["themes"])
                }
                
                print(f"‚úì Successfully identified {len(result['themes'])} research themes")
                print(f"‚úì All themes have insights and research directions")
                
        except Exception as e:
            self.test_results["task_6_3_tests"]["topic_clustering"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["topic_clustering"]["details"] = {"error": str(e)}
            self.test_results["task_6_3_tests"]["theme_identification"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["theme_identification"]["details"] = {"error": str(e)}
            print(f"‚úó Topic clustering and theme identification failed: {e}")
    
    async def test_research_gap_detection(self):
        """Test comprehensive research gap detection"""
        print("Testing research gap detection...")
        
        try:
            test_items = self.create_comprehensive_test_data()
            user_id = "test_user_123"
            
            with patch.object(self.service, '_get_user_items_for_analysis', return_value=test_items):
                # Test gap detection
                result = await self.service.detect_research_gaps(
                    user_id=user_id,
                    gap_types=["temporal", "topical", "methodological"]
                )
                
                # Verify gap detection results
                assert "gaps_detected" in result
                assert "recommendations" in result
                assert result["user_id"] == user_id
                assert result["gap_types"] == ["temporal", "topical", "methodological"]
                
                gaps_detected = result["gaps_detected"]
                
                # Verify temporal gaps
                if "temporal" in gaps_detected:
                    temporal_gaps = gaps_detected["temporal"]
                    assert "gaps" in temporal_gaps
                    assert "analysis" in temporal_gaps
                
                # Verify topical gaps
                if "topical" in gaps_detected:
                    topical_gaps = gaps_detected["topical"]
                    assert "gaps" in topical_gaps
                    assert "analysis" in topical_gaps
                    assert "suggestions" in topical_gaps
                
                # Verify methodological gaps
                if "methodological" in gaps_detected:
                    method_gaps = gaps_detected["methodological"]
                    assert "gaps" in method_gaps
                    assert "analysis" in method_gaps
                    assert "recommendations" in method_gaps
                
                # Verify recommendations
                recommendations = result["recommendations"]
                assert isinstance(recommendations, list)
                
                self.test_results["task_6_3_tests"]["gap_detection"]["status"] = "passed"
                self.test_results["task_6_3_tests"]["gap_detection"]["details"] = {
                    "gap_types_analyzed": len(result["gap_types"]),
                    "recommendations_generated": len(recommendations),
                    "temporal_gaps_found": len(gaps_detected.get("temporal", {}).get("gaps", [])),
                    "topical_gaps_found": len(gaps_detected.get("topical", {}).get("gaps", {}).get("underrepresented_topics", [])),
                    "methodological_gaps_found": len(gaps_detected.get("methodological", {}).get("gaps", {}).get("missing_methodologies", []))
                }
                
                print(f"‚úì Successfully detected gaps across {len(result['gap_types'])} categories")
                print(f"‚úì Generated {len(recommendations)} gap-filling recommendations")
                
        except Exception as e:
            self.test_results["task_6_3_tests"]["gap_detection"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["gap_detection"]["details"] = {"error": str(e)}
            print(f"‚úó Research gap detection failed: {e}")
    
    async def test_trend_analysis_and_predictions(self):
        """Test comprehensive trend analysis with predictions"""
        print("Testing trend analysis and predictions...")
        
        try:
            test_items = self.create_comprehensive_test_data()
            user_id = "test_user_123"
            
            with patch.object(self.service, '_get_user_items_for_analysis', return_value=test_items):
                # Test trend analysis
                result = await self.service.analyze_research_trends(
                    user_id=user_id,
                    trend_types=["temporal", "topical", "citation", "collaboration"],
                    time_window_years=5
                )
                
                # Verify trend analysis results
                assert "trends" in result
                assert "predictions" in result
                assert result["user_id"] == user_id
                assert result["trend_types"] == ["temporal", "topical", "citation", "collaboration"]
                
                trends = result["trends"]
                predictions = result["predictions"]
                
                # Verify temporal trends
                if "temporal" in trends:
                    temporal = trends["temporal"]
                    assert "publication_timeline" in temporal or "error" not in temporal
                
                # Verify topical trends
                if "topical" in trends:
                    topical = trends["topical"]
                    assert "topic_evolution" in topical or "error" not in topical
                
                # Verify citation trends
                if "citation" in trends:
                    citation = trends["citation"]
                    assert "venue_analysis" in citation or "error" not in citation
                
                # Verify collaboration trends
                if "collaboration" in trends:
                    collaboration = trends["collaboration"]
                    assert "collaboration_metrics" in collaboration or "error" not in collaboration
                
                # Verify predictions structure
                assert isinstance(predictions, dict)
                expected_prediction_types = ["temporal_predictions", "topical_predictions", "collaboration_predictions", "confidence_scores"]
                for pred_type in expected_prediction_types:
                    assert pred_type in predictions
                
                self.test_results["task_6_3_tests"]["trend_analysis"]["status"] = "passed"
                self.test_results["task_6_3_tests"]["trend_analysis"]["details"] = {
                    "trend_types_analyzed": len(result["trend_types"]),
                    "time_window_years": result["time_window_years"],
                    "predictions_generated": len([p for pred_list in predictions.values() if isinstance(pred_list, list) for p in pred_list]),
                    "confidence_scores": predictions.get("confidence_scores", {})
                }
                
                print(f"‚úì Successfully analyzed {len(result['trend_types'])} trend types")
                print(f"‚úì Generated comprehensive predictions with confidence scores")
                
        except Exception as e:
            self.test_results["task_6_3_tests"]["trend_analysis"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["trend_analysis"]["details"] = {"error": str(e)}
            print(f"‚úó Trend analysis failed: {e}")
    
    async def test_research_directions_generation(self):
        """Test research direction suggestions"""
        print("Testing research direction generation...")
        
        try:
            # Test theme-based research directions
            test_theme = {
                "theme_id": "theme_0",
                "theme_name": "Machine Learning in Healthcare",
                "keywords": ["machine learning", "healthcare", "medical diagnosis", "AI"],
                "summary": "Research focused on ML applications in medical settings",
                "item_count": 3,
                "items": [
                    {"item_id": "item_0", "title": "ML in Healthcare", "year": 2023},
                    {"item_id": "item_1", "title": "AI Diagnosis", "year": 2022}
                ],
                "coherence_score": 0.8
            }
            
            # Test insights generation
            insights = await self.service._generate_theme_insights(test_theme)
            assert isinstance(insights, list)
            assert len(insights) > 0
            
            # Test research directions generation
            directions = await self.service._suggest_research_directions(test_theme)
            assert isinstance(directions, list)
            assert len(directions) > 0
            
            self.test_results["task_6_3_tests"]["research_directions"]["status"] = "passed"
            self.test_results["task_6_3_tests"]["research_directions"]["details"] = {
                "insights_generated": len(insights),
                "directions_suggested": len(directions),
                "theme_coherence": test_theme["coherence_score"]
            }
            
            print(f"‚úì Generated {len(insights)} theme insights")
            print(f"‚úì Suggested {len(directions)} research directions")
            
        except Exception as e:
            self.test_results["task_6_3_tests"]["research_directions"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["research_directions"]["details"] = {"error": str(e)}
            print(f"‚úó Research directions generation failed: {e}")
    
    async def test_integration_and_comprehensive_analysis(self):
        """Test integration of all research insights features"""
        print("Testing comprehensive research landscape analysis...")
        
        try:
            test_items = self.create_comprehensive_test_data()
            user_id = "test_user_123"
            
            with patch.object(self.service, '_get_user_items_for_analysis', return_value=test_items):
                # Test comprehensive research landscape analysis
                result = await self.service.analyze_research_landscape(
                    user_id=user_id,
                    analysis_types=["topics", "trends", "gaps", "networks"]
                )
                
                # Verify comprehensive analysis results
                assert "results" in result
                assert result["user_id"] == user_id
                assert result["analysis_types"] == ["topics", "trends", "gaps", "networks"]
                
                results = result["results"]
                
                # Verify all analysis types are present
                for analysis_type in ["topics", "trends", "gaps", "networks"]:
                    assert analysis_type in results
                
                # Verify topics analysis
                topics_result = results["topics"]
                assert "total_topics" in topics_result or "error" not in topics_result
                
                # Verify trends analysis
                trends_result = results["trends"]
                assert "publication_trends" in trends_result or "error" not in trends_result
                
                # Verify gaps analysis
                gaps_result = results["gaps"]
                assert "temporal_gaps" in gaps_result or "error" not in gaps_result
                
                # Verify networks analysis
                networks_result = results["networks"]
                assert "author_network" in networks_result or "error" not in networks_result
                
                self.test_results["task_6_3_tests"]["integration_tests"]["status"] = "passed"
                self.test_results["task_6_3_tests"]["integration_tests"]["details"] = {
                    "analysis_types_completed": len(result["analysis_types"]),
                    "total_items_analyzed": result["total_items"],
                    "comprehensive_analysis": True,
                    "all_components_working": all(
                        "error" not in str(results[analysis_type]) 
                        for analysis_type in result["analysis_types"]
                    )
                }
                
                print(f"‚úì Successfully completed comprehensive analysis of {result['total_items']} items")
                print(f"‚úì All {len(result['analysis_types'])} analysis types working correctly")
                
        except Exception as e:
            self.test_results["task_6_3_tests"]["integration_tests"]["status"] = "failed"
            self.test_results["task_6_3_tests"]["integration_tests"]["details"] = {"error": str(e)}
            print(f"‚úó Integration tests failed: {e}")
    
    async def run_all_tests(self):
        """Run all Task 6.3 verification tests"""
        print("=" * 60)
        print("TASK 6.3 VERIFICATION: Research Insights and Gap Analysis")
        print("=" * 60)
        
        # Run all test methods
        await self.test_topic_clustering_and_theme_identification()
        await self.test_research_gap_detection()
        await self.test_trend_analysis_and_predictions()
        await self.test_research_directions_generation()
        await self.test_integration_and_comprehensive_analysis()
        
        # Generate summary
        self.generate_test_summary()
    
    def generate_test_summary(self):
        """Generate and display test summary"""
        print("\n" + "=" * 60)
        print("TASK 6.3 VERIFICATION SUMMARY")
        print("=" * 60)
        
        total_tests = len(self.test_results["task_6_3_tests"])
        passed_tests = len([t for t in self.test_results["task_6_3_tests"].values() if t["status"] == "passed"])
        failed_tests = len([t for t in self.test_results["task_6_3_tests"].values() if t["status"] == "failed"])
        
        print(f"Total Tests: {total_tests}")
        print(f"Passed: {passed_tests}")
        print(f"Failed: {failed_tests}")
        print(f"Success Rate: {(passed_tests/total_tests)*100:.1f}%")
        
        print("\nDetailed Results:")
        for test_name, result in self.test_results["task_6_3_tests"].items():
            status_symbol = "‚úì" if result["status"] == "passed" else "‚úó"
            print(f"{status_symbol} {test_name.replace('_', ' ').title()}: {result['status']}")
            
            if result["status"] == "passed" and result["details"]:
                for key, value in result["details"].items():
                    if key != "error":
                        print(f"    {key}: {value}")
            elif result["status"] == "failed" and "error" in result["details"]:
                print(f"    Error: {result['details']['error']}")
        
        # Task 6.3 specific requirements verification
        print("\n" + "-" * 40)
        print("TASK 6.3 REQUIREMENTS VERIFICATION")
        print("-" * 40)
        
        requirements_met = {
            "Topic clustering and theme identification": passed_tests >= 2,
            "Research gap detection algorithms": self.test_results["task_6_3_tests"]["gap_detection"]["status"] == "passed",
            "Trend analysis and research direction suggestions": self.test_results["task_6_3_tests"]["trend_analysis"]["status"] == "passed",
            "Comprehensive testing coverage": passed_tests >= 4,
            "Integration with existing features": self.test_results["task_6_3_tests"]["integration_tests"]["status"] == "passed"
        }
        
        for requirement, met in requirements_met.items():
            status_symbol = "‚úì" if met else "‚úó"
            print(f"{status_symbol} {requirement}")
        
        all_requirements_met = all(requirements_met.values())
        
        print(f"\nTask 6.3 Implementation: {'COMPLETE' if all_requirements_met else 'INCOMPLETE'}")
        
        if all_requirements_met:
            print("\nüéâ All Task 6.3 requirements have been successfully implemented!")
            print("   - Topic clustering and theme identification working")
            print("   - Research gap detection algorithms implemented")
            print("   - Trend analysis with predictions functional")
            print("   - Research direction suggestions generated")
            print("   - Comprehensive testing coverage achieved")
        else:
            print(f"\n‚ö†Ô∏è  Task 6.3 implementation incomplete. {failed_tests} test(s) failed.")
        
        # Save results to file
        with open("task_6_3_verification_results.json", "w") as f:
            json.dump(self.test_results, f, indent=2, default=str)
        
        print(f"\nDetailed results saved to: task_6_3_verification_results.json")


async def main():
    """Main test execution function"""
    tester = TestZoteroResearchInsightsTask63()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())