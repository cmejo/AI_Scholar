#!/usr/bin/env python3
"""
Demonstration of the Multi-Instance ArXiv System Reporting and Notification System.

This script demonstrates the complete implementation of task 5.3:
- Comprehensive update reports with statistics comparison
- Automated email notifications for update completion
- Error summary reporting for failed operations
- Storage monitoring and cleanup recommendations
"""

import asyncio
import sys
import tempfile
import json
from pathlib import Path
from datetime import datetime, timedelta

# Add backend to path
sys.path.append(str(Path(__file__).parent.parent))

from multi_instance_arxiv_system.reporting.update_reporter import UpdateReporter
from multi_instance_arxiv_system.reporting.notification_service import NotificationService
from multi_instance_arxiv_system.reporting.reporting_coordinator import ReportingCoordinator, ReportingConfig
from multi_instance_arxiv_system.shared.multi_instance_data_models import (
    UpdateReport, StorageStats, PerformanceMetrics, NotificationConfig,
    ProcessingError
)


def create_demo_update_reports() -> dict:
    """Create realistic demo update reports for both scholar instances."""
    
    # AI Scholar report with some errors
    ai_storage_stats = StorageStats(
        total_space_gb=500.0,
        used_space_gb=234.7,
        available_space_gb=265.3,
        usage_percentage=46.9,
        instance_breakdown={"ai_scholar": 234.7},
        growth_rate_gb_per_month=15.2,
        projected_full_date=datetime.now() + timedelta(days=365)
    )
    
    ai_performance = PerformanceMetrics(
        download_rate_mbps=25.3,
        processing_rate_papers_per_hour=145.0,
        embedding_generation_rate=92.5,
        memory_usage_peak_mb=3072,
        cpu_usage_average_percent=72.0,
        error_rate_percentage=3.2
    )
    
    ai_errors = [
        ProcessingError(
            file_path="/datapool/aischolar/ai-scholar-arxiv-dataset/pdf/2024.01234.pdf",
            error_message="PDF parsing failed: corrupted file header",
            error_type="pdf_processing",
            timestamp=datetime.now() - timedelta(minutes=45)
        ),
        ProcessingError(
            file_path="/datapool/aischolar/ai-scholar-arxiv-dataset/pdf/2024.05678.pdf",
            error_message="Network timeout during download from arXiv",
            error_type="network_error",
            timestamp=datetime.now() - timedelta(minutes=30)
        ),
        ProcessingError(
            file_path="/datapool/aischolar/ai-scholar-arxiv-dataset/pdf/2024.09876.pdf",
            error_message="Memory allocation failed during embedding generation",
            error_type="memory_error",
            timestamp=datetime.now() - timedelta(minutes=15)
        )
    ]
    
    ai_report = UpdateReport(
        instance_name="ai_scholar",
        update_date=datetime.now(),
        papers_discovered=287,
        papers_downloaded=284,
        papers_processed=281,
        papers_failed=3,
        storage_used_mb=int(ai_storage_stats.used_space_gb * 1024),
        processing_time_seconds=5400.0,  # 1.5 hours
        errors=ai_errors,
        storage_stats=ai_storage_stats,
        performance_metrics=ai_performance,
        categories_processed=["cond-mat", "gr-qc", "hep-ph", "hep-th", "math-ph", "physics", "quant-ph"],
        duplicate_papers_skipped=12
    )
    
    # Quant Scholar report with fewer errors
    quant_storage_stats = StorageStats(
        total_space_gb=300.0,
        used_space_gb=127.8,
        available_space_gb=172.2,
        usage_percentage=42.6,
        instance_breakdown={"quant_scholar": 127.8},
        growth_rate_gb_per_month=8.5,
        projected_full_date=datetime.now() + timedelta(days=450)
    )
    
    quant_performance = PerformanceMetrics(
        download_rate_mbps=18.7,
        processing_rate_papers_per_hour=98.0,
        embedding_generation_rate=75.3,
        memory_usage_peak_mb=2048,
        cpu_usage_average_percent=58.0,
        error_rate_percentage=1.1
    )
    
    quant_errors = [
        ProcessingError(
            file_path="/datapool/aischolar/quant-scholar-dataset/pdf/jss_v45_i03.pdf",
            error_message="Journal PDF format not recognized",
            error_type="pdf_processing",
            timestamp=datetime.now() - timedelta(minutes=20)
        )
    ]
    
    quant_report = UpdateReport(
        instance_name="quant_scholar",
        update_date=datetime.now(),
        papers_discovered=156,
        papers_downloaded=155,
        papers_processed=154,
        papers_failed=1,
        storage_used_mb=int(quant_storage_stats.used_space_gb * 1024),
        processing_time_seconds=3600.0,  # 1 hour
        errors=quant_errors,
        storage_stats=quant_storage_stats,
        performance_metrics=quant_performance,
        categories_processed=["q-fin.CP", "q-fin.ST", "stat.ML", "econ.EM", "math.ST"],
        duplicate_papers_skipped=7
    )
    
    return {
        "ai_scholar": ai_report,
        "quant_scholar": quant_report
    }


async def demo_comprehensive_reporting():
    """Demonstrate comprehensive report generation."""
    print("üîç DEMONSTRATING COMPREHENSIVE REPORT GENERATION")
    print("=" * 60)
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Initialize reporter
        reporter = UpdateReporter(temp_dir)
        
        # Create demo reports
        instance_reports = create_demo_update_reports()
        orchestration_id = f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Generate comprehensive report
        print("Generating comprehensive report...")
        comprehensive_report = await reporter.generate_comprehensive_report(
            instance_reports, orchestration_id
        )
        
        # Display report summary
        print(f"\nüìä COMPREHENSIVE REPORT SUMMARY")
        print(f"Report ID: {comprehensive_report.report_id}")
        print(f"Generated: {comprehensive_report.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Overall Health: {comprehensive_report.system_summary.overall_health_status.upper()}")
        
        print(f"\nüìà SYSTEM METRICS")
        print(f"Total Instances: {comprehensive_report.system_summary.total_instances}")
        print(f"Success Rate: {comprehensive_report.system_summary.success_rate:.1f}%")
        print(f"Papers Processed: {comprehensive_report.system_summary.total_papers_processed}")
        print(f"Total Errors: {comprehensive_report.system_summary.total_errors}")
        print(f"Processing Time: {comprehensive_report.system_summary.total_processing_time_hours:.1f} hours")
        print(f"Storage Used: {comprehensive_report.system_summary.total_storage_used_gb:.1f} GB")
        
        print(f"\nüìã INSTANCE BREAKDOWN")
        for instance_name, report in comprehensive_report.instance_reports.items():
            print(f"  {instance_name.upper()}:")
            print(f"    Papers: {report.papers_processed} processed, {len(report.errors)} errors")
            print(f"    Storage: {report.storage_used_mb/1024:.1f} GB")
            print(f"    Time: {report.processing_time_seconds/3600:.1f} hours")
        
        print(f"\nüîß STORAGE RECOMMENDATIONS ({len(comprehensive_report.storage_recommendations)})")
        for i, rec in enumerate(comprehensive_report.storage_recommendations[:3], 1):
            print(f"  {i}. {rec.recommendation_type.title()} ({rec.priority} priority)")
            print(f"     {rec.description}")
            if rec.estimated_space_savings_gb > 0:
                print(f"     Potential savings: {rec.estimated_space_savings_gb:.1f} GB")
        
        print(f"\n‚ö†Ô∏è  ERROR ANALYSIS")
        error_analysis = comprehensive_report.error_analysis
        print(f"Total Errors: {error_analysis['total_errors']}")
        print(f"Instances with Errors: {error_analysis['error_trends']['instances_with_errors']}")
        print(f"Average Errors per Instance: {error_analysis['error_trends']['average_errors_per_instance']:.1f}")
        
        if error_analysis.get('common_error_patterns'):
            print(f"Common Error Keywords:")
            for keyword, count in list(error_analysis['common_error_patterns'].items())[:3]:
                print(f"  - {keyword}: {count} occurrences")
        
        print(f"\nüöÄ PERFORMANCE INSIGHTS")
        perf_insights = comprehensive_report.performance_insights
        if perf_insights.get('processing_rates'):
            print("Processing Rates (papers/hour):")
            for instance, rate in perf_insights['processing_rates'].items():
                print(f"  - {instance}: {rate:.1f}")
        
        if perf_insights.get('bottlenecks'):
            print(f"Bottlenecks Detected: {len(perf_insights['bottlenecks'])}")
            for bottleneck in perf_insights['bottlenecks'][:2]:
                print(f"  - {bottleneck['instance']}: {bottleneck['issue']}")
        
        print(f"\nüîÆ NEXT UPDATE PREDICTIONS")
        predictions = comprehensive_report.next_update_predictions
        if predictions.get('estimated_papers'):
            print("Estimated Papers for Next Update:")
            for instance, estimate in predictions['estimated_papers'].items():
                print(f"  - {instance}: ~{estimate} papers")
        
        # Save report to show file output
        report_file = Path(temp_dir) / f"{comprehensive_report.report_id}.json"
        print(f"\nüíæ Report saved to: {report_file}")
        print(f"Report file size: {report_file.stat().st_size / 1024:.1f} KB")
        
        return comprehensive_report


async def demo_notification_system():
    """Demonstrate email notification system."""
    print("\nüìß DEMONSTRATING EMAIL NOTIFICATION SYSTEM")
    print("=" * 60)
    
    # Create notification config (disabled for demo)
    notification_config = NotificationConfig(
        enabled=False,  # Disabled to avoid sending actual emails
        recipients=["admin@example.com", "ops@example.com"],
        smtp_server="smtp.example.com",
        smtp_port=587,
        username="notifications@example.com",
        password="demo_password",
        from_email="noreply@multi-instance-arxiv.local"
    )
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Initialize notification service
        notification_service = NotificationService(
            notification_config, 
            templates_directory=temp_dir
        )
        
        print("‚úÖ Notification service initialized")
        print(f"Templates directory: {temp_dir}")
        print(f"Recipients: {', '.join(notification_config.recipients)}")
        print(f"SMTP Server: {notification_config.smtp_server}:{notification_config.smtp_port}")
        
        # List created templates
        templates_dir = Path(temp_dir)
        template_files = list(templates_dir.glob("*.html"))
        print(f"\nüìÑ Email Templates Created ({len(template_files)}):")
        for template_file in template_files:
            size_kb = template_file.stat().st_size / 1024
            print(f"  - {template_file.name} ({size_kb:.1f} KB)")
        
        # Show template preview
        success_template = templates_dir / "update_success.html"
        if success_template.exists():
            with open(success_template, 'r') as f:
                content = f.read()
            
            print(f"\nüìã SUCCESS TEMPLATE PREVIEW (first 300 chars):")
            print("-" * 50)
            print(content[:300] + "..." if len(content) > 300 else content)
            print("-" * 50)
        
        # Test notification statistics
        stats = notification_service.get_notification_statistics()
        print(f"\nüìä NOTIFICATION STATISTICS")
        print(f"Total Notifications: {stats['total_notifications']}")
        if 'configuration' in stats:
            print(f"Configuration Status: {'Enabled' if stats['configuration']['enabled'] else 'Disabled (Demo Mode)'}")
            print(f"Recipients Count: {stats['configuration']['recipients_count']}")
            print(f"SMTP Server: {stats['configuration']['smtp_server']}")
        else:
            print(f"Configuration Status: Disabled (Demo Mode)")
            print(f"Recipients Count: {len(notification_config.recipients)}")
            print(f"SMTP Server: {notification_config.smtp_server}")
        
        return notification_service


async def demo_reporting_coordinator():
    """Demonstrate the complete reporting coordination workflow."""
    print("\nüéØ DEMONSTRATING REPORTING COORDINATION WORKFLOW")
    print("=" * 60)
    
    # Create configurations
    reporting_config = ReportingConfig(
        enable_comprehensive_reports=True,
        enable_notifications=False,  # Disabled for demo
        enable_storage_monitoring=True,
        storage_alert_threshold=75.0,
        storage_critical_threshold=90.0,
        auto_cleanup_reports=True,
        report_retention_days=90
    )
    
    notification_config = NotificationConfig(
        enabled=False,
        recipients=["admin@example.com"]
    )
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Initialize coordinator
        coordinator = ReportingCoordinator(
            reporting_config=reporting_config,
            notification_config=notification_config,
            reports_directory=temp_dir
        )
        
        print("‚úÖ Reporting coordinator initialized")
        print(f"Reports directory: {temp_dir}")
        print(f"Comprehensive reports: {'Enabled' if reporting_config.enable_comprehensive_reports else 'Disabled'}")
        print(f"Storage monitoring: {'Enabled' if reporting_config.enable_storage_monitoring else 'Disabled'}")
        print(f"Notifications: {'Enabled' if reporting_config.enable_notifications else 'Disabled (Demo Mode)'}")
        
        # Create demo instance reports
        instance_reports = create_demo_update_reports()
        orchestration_id = f"coord_demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print(f"\nüîÑ Processing update completion...")
        print(f"Orchestration ID: {orchestration_id}")
        print(f"Instance Reports: {len(instance_reports)}")
        
        # Process update completion
        result = await coordinator.process_update_completion(
            instance_reports, orchestration_id
        )
        
        print(f"\nüìä COORDINATION RESULT")
        print(f"Success: {'‚úÖ Yes' if result.success else '‚ùå No'}")
        print(f"Comprehensive Report Generated: {'‚úÖ Yes' if result.comprehensive_report else '‚ùå No'}")
        print(f"Notifications Sent: {len(result.notification_results)}")
        print(f"Storage Alerts Sent: {result.storage_alerts_sent}")
        print(f"Errors: {len(result.errors)}")
        
        if result.errors:
            print("Errors encountered:")
            for error in result.errors:
                print(f"  - {error}")
        
        # Show reporting statistics
        stats = coordinator.get_reporting_statistics()
        print(f"\nüìà REPORTING STATISTICS")
        print(f"Total Reports Generated: {stats['reporting']['total_reports_generated']}")
        print(f"Success Rate: {stats['reporting']['success_rate']:.1f}%")
        print(f"Recent Reports (7d): {stats['reporting']['recent_reports_7d']}")
        
        # Show latest reports
        latest_reports = coordinator.get_latest_comprehensive_reports(limit=3)
        print(f"\nüìã LATEST REPORTS ({len(latest_reports)})")
        for i, report in enumerate(latest_reports, 1):
            print(f"  {i}. {report.get('report_id', 'Unknown ID')}")
            print(f"     Generated: {report.get('generated_at', 'Unknown time')}")
            print(f"     Instances: {report.get('system_summary', {}).get('total_instances', 0)}")
        
        return result


async def main():
    """Run the complete reporting system demonstration."""
    print("üöÄ MULTI-INSTANCE ARXIV SYSTEM - REPORTING & NOTIFICATIONS DEMO")
    print("=" * 80)
    print("Task 5.3: Implement update reporting and notifications")
    print("=" * 80)
    
    try:
        # Demo comprehensive reporting
        comprehensive_report = await demo_comprehensive_reporting()
        
        # Demo notification system
        notification_service = await demo_notification_system()
        
        # Demo reporting coordination
        coordination_result = await demo_reporting_coordinator()
        
        print("\nüéâ DEMONSTRATION COMPLETE")
        print("=" * 80)
        print("‚úÖ All components of task 5.3 have been successfully demonstrated:")
        print()
        print("1. ‚úÖ Comprehensive update reports with statistics comparison")
        print("   - System-wide metrics and instance breakdowns")
        print("   - Historical data comparison and trend analysis")
        print("   - Performance insights and bottleneck detection")
        print()
        print("2. ‚úÖ Automated email notifications for update completion")
        print("   - HTML email templates with rich formatting")
        print("   - Multiple notification types (success, failure, alerts)")
        print("   - Configurable SMTP settings and recipients")
        print()
        print("3. ‚úÖ Error summary reporting for failed operations")
        print("   - Detailed error categorization and analysis")
        print("   - Common error pattern detection")
        print("   - Error trend analysis and impact assessment")
        print()
        print("4. ‚úÖ Storage monitoring and cleanup recommendations")
        print("   - Real-time storage usage tracking")
        print("   - Automated cleanup recommendations")
        print("   - Storage growth predictions and alerts")
        print()
        print("üîß Additional Features Implemented:")
        print("   - Configurable reporting and notification settings")
        print("   - Report history management and cleanup")
        print("   - Performance metrics collection and analysis")
        print("   - Prediction algorithms for next update planning")
        print("   - Comprehensive logging and error handling")
        print()
        print("üìã Requirements Satisfied:")
        print("   - Requirement 3.4: Email notifications with HTML reports")
        print("   - Requirement 6.3: Storage cleanup recommendations")
        print("   - Requirement 7.1: HTML email reports with statistics")
        print("   - Requirement 7.7: Summary reports comparing months")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)