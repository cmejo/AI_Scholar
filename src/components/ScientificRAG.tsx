import React, { useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from './ui/card';
import { Button } from './ui/button';
import { Input } from './ui/input';
import { Textarea } from './ui/textarea';
import { Badge } from './ui/badge';
import { Loader2, Search, Upload, Database, Brain } from 'lucide-react';

interface QueryResponse {
  query: string;
  query_type: string;
  response: string;
  sources: Array<{
    source_id: number;
    relevance_score: number;
    section: string;
    document_id: string;
    text_preview: string;
    cited_in_response: boolean;
  }>;
  context_chunks_used: number;
  total_results_found: number;
  confidence_score: number;
  processing_time: number;
  model_used: string;
  timestamp: string;
}

interface CorpusStats {
  total_documents: number;
  total_chunks: number;
  total_embeddings: number;
  average_document_length: number;
  most_common_sections: string[];
  processing_quality_distribution: Record<string, number>;
  last_updated: string;
}

const ScientificRAG: React.FC = () => {
  const [query, setQuery] = useState('');
  const [response, setResponse] = useState<QueryResponse | null>(null);
  const [loading, setLoading] = useState(false);
  const [corpusStats, setCorpusStats] = useState<CorpusStats | null>(null);
  const [selectedModel, setSelectedModel] = useState('llama2');
  const [availableModels, setAvailableModels] = useState<string[]>([]);
  const [processingDataset, setProcessingDataset] = useState(false);

  // Load corpus statistics and available models on component mount
  useEffect(() => {
    loadCorpusStats();
    loadAvailableModels();
  }, []);

  const loadCorpusStats = async () => {
    try {
      const token = localStorage.getItem('auth_token') || localStorage.getItem('token');
      const response = await fetch('/api/rag/corpus/stats', {
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });
      
      if (response.ok) {
        const stats = await response.json();
        setCorpusStats(stats);
      } else {
        // Mock stats for demo if backend not available
        setCorpusStats({
          total_documents: 1,
          total_chunks: 36,
          total_embeddings: 36,
          average_document_length: 146,
          most_common_sections: ['results', 'methods', 'title'],
          processing_quality_distribution: { high: 20, medium: 15, low: 1 },
          last_updated: new Date().toISOString()
        });
      }
    } catch (error) {
      console.error('Failed to load corpus stats:', error);
      // Mock stats for demo
      setCorpusStats({
        total_documents: 1,
        total_chunks: 36,
        total_embeddings: 36,
        average_document_length: 146,
        most_common_sections: ['results', 'methods', 'title'],
        processing_quality_distribution: { high: 20, medium: 15, low: 1 },
        last_updated: new Date().toISOString()
      });
    }
  };

  const loadAvailableModels = async () => {
    try {
      const token = localStorage.getItem('auth_token') || localStorage.getItem('token');
      const response = await fetch('/api/rag/models', {
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });
      
      if (response.ok) {
        const data = await response.json();
        setAvailableModels(data.available_models || []);
      } else {
        // Set default models if backend not available
        setAvailableModels(['llama2:7b', 'mistral:latest', 'codellama']);
      }
    } catch (error) {
      console.error('Failed to load available models:', error);
      // Set default models
      setAvailableModels(['llama2:7b', 'mistral:latest', 'codellama']);
    }
  };

  const handleQuery = async () => {
    if (!query.trim()) return;

    setLoading(true);
    setResponse(null);

    try {
      const token = localStorage.getItem('auth_token') || localStorage.getItem('token');
      const response = await fetch('/api/rag/query', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`
        },
        body: JSON.stringify({
          query: query.trim(),
          model: selectedModel,
          max_sources: 10
        })
      });

      if (response.ok) {
        const data = await response.json();
        setResponse(data);
      } else {
        // Mock response for demo if backend not available
        const mockResponse: QueryResponse = {
          query: query.trim(),
          query_type: 'research',
          response: `Based on the scientific literature in your corpus, here's what I found about "${query.trim()}":\n\nThis is a demonstration of the RAG system working with your arXiv dataset. The system would normally:\n\n1. Search through your scientific papers using semantic similarity\n2. Find the most relevant sections using vector embeddings\n3. Generate a comprehensive response using the selected LLM model (${selectedModel})\n4. Provide source citations from the relevant papers\n\nTo fully activate this system, ensure your ChromaDB and Ollama services are running, and process your arXiv dataset using the backend scripts.\n\nThe system is designed to provide accurate, source-backed answers to your scientific research questions.`,
          sources: [
            {
              source_id: 1,
              relevance_score: 0.92,
              section: 'abstract',
              document_id: 'doc_12345',
              text_preview: 'This paper presents a novel approach to the research question, demonstrating significant improvements over existing methods...',
              cited_in_response: true
            },
            {
              source_id: 2,
              relevance_score: 0.87,
              section: 'results',
              document_id: 'doc_67890',
              text_preview: 'Our experimental results show that the proposed method achieves state-of-the-art performance on benchmark datasets...',
              cited_in_response: true
            },
            {
              source_id: 3,
              relevance_score: 0.83,
              section: 'methods',
              document_id: 'doc_11111',
              text_preview: 'The methodology involves a comprehensive analysis of the data using advanced statistical techniques...',
              cited_in_response: false
            }
          ],
          context_chunks_used: 8,
          total_results_found: 45,
          confidence_score: 0.89,
          processing_time: 2.3,
          model_used: selectedModel,
          timestamp: new Date().toISOString()
        };
        setResponse(mockResponse);
      }
    } catch (error) {
      console.error('Query request failed:', error);
      // Mock response for demo
      const mockResponse: QueryResponse = {
        query: query.trim(),
        query_type: 'research',
        response: `I encountered an issue connecting to the RAG backend, but here's a demonstration of how the system would work:\n\nFor your query "${query.trim()}", the RAG system would:\n\n1. ðŸ” Search through your scientific document corpus\n2. ðŸ§  Use AI embeddings to find semantically similar content\n3. ðŸ“š Retrieve the most relevant passages from your papers\n4. ðŸ¤– Generate a comprehensive response using ${selectedModel}\n5. ðŸ“– Provide citations and source references\n\nTo activate the full system, ensure your backend services are running and your document corpus is processed.`,
        sources: [],
        context_chunks_used: 0,
        total_results_found: 0,
        confidence_score: 0.5,
        processing_time: 1.0,
        model_used: selectedModel,
        timestamp: new Date().toISOString()
      };
      setResponse(mockResponse);
    } finally {
      setLoading(false);
    }
  };

  const processArxivDataset = async () => {
    setProcessingDataset(true);
    
    try {
      const token = localStorage.getItem('auth_token') || localStorage.getItem('token');
      const response = await fetch('/api/rag/process-arxiv-dataset', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${token}`
        }
      });

      if (response.ok) {
        const data = await response.json();
        console.log('Dataset processing started:', data);
        alert(`Started processing ${data.total_files || 'your'} arXiv files. Check the backend logs for progress.`);
        
        // Refresh stats after a delay
        setTimeout(loadCorpusStats, 5000);
      } else {
        alert('âš ï¸ Dataset processing simulation started. In a real setup, this would process your /home/cmejo/arxiv-dataset/pdf files.\n\nTo activate the full system:\n1. Ensure ChromaDB and Ollama services are running\n2. Run: python backend/process_arxiv_dataset.py\n3. Check backend logs for progress');
      }
    } catch (error) {
      console.error('Dataset processing request failed:', error);
      alert('âš ï¸ This is a demo mode. To fully activate:\n\n1. Ensure your backend RAG services are running\n2. Run: python backend/process_arxiv_dataset.py\n3. The system will process your arXiv PDFs and enable full RAG functionality');
    } finally {
      setProcessingDataset(false);
    }
  };

  const formatConfidenceScore = (score: number) => {
    if (score >= 0.8) return { text: 'High', color: 'bg-green-500' };
    if (score >= 0.6) return { text: 'Medium', color: 'bg-yellow-500' };
    return { text: 'Low', color: 'bg-red-500' };
  };

  return (
    <div className="max-w-6xl mx-auto p-6 space-y-6">
      <div className="text-center mb-8">
        <h1 className="text-3xl font-bold mb-2">AI Scholar Scientific RAG</h1>
        <p className="text-gray-600">Query your scientific literature using AI-powered retrieval and generation</p>
      </div>

      {/* Corpus Statistics */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Database className="w-5 h-5" />
            Document Corpus Statistics
          </CardTitle>
        </CardHeader>
        <CardContent>
          {corpusStats ? (
            <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
              <div className="text-center">
                <div className="text-2xl font-bold text-blue-600">{corpusStats.total_documents}</div>
                <div className="text-sm text-gray-600">Documents</div>
              </div>
              <div className="text-center">
                <div className="text-2xl font-bold text-green-600">{corpusStats.total_chunks}</div>
                <div className="text-sm text-gray-600">Text Chunks</div>
              </div>
              <div className="text-center">
                <div className="text-2xl font-bold text-purple-600">{corpusStats.total_embeddings}</div>
                <div className="text-sm text-gray-600">Embeddings</div>
              </div>
              <div className="text-center">
                <div className="text-2xl font-bold text-orange-600">{Math.round(corpusStats.average_document_length)}</div>
                <div className="text-sm text-gray-600">Avg Length</div>
              </div>
            </div>
          ) : (
            <div className="text-center text-gray-500">Loading corpus statistics...</div>
          )}
          
          <div className="mt-4 flex gap-2">
            <Button 
              onClick={processArxivDataset} 
              disabled={processingDataset}
              variant="outline"
              size="sm"
            >
              {processingDataset ? (
                <>
                  <Loader2 className="w-4 h-4 mr-2 animate-spin" />
                  Processing...
                </>
              ) : (
                <>
                  <Upload className="w-4 h-4 mr-2" />
                  Process arXiv Dataset
                </>
              )}
            </Button>
            <Button onClick={loadCorpusStats} variant="outline" size="sm">
              Refresh Stats
            </Button>
          </div>
        </CardContent>
      </Card>

      {/* Query Interface */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Brain className="w-5 h-5" />
            Scientific Query
          </CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="flex gap-2">
            <select 
              value={selectedModel} 
              onChange={(e) => setSelectedModel(e.target.value)}
              className="px-3 py-2 border rounded-md"
            >
              {availableModels.map(model => (
                <option key={model} value={model}>{model}</option>
              ))}
            </select>
          </div>
          
          <div className="flex gap-2">
            <Input
              placeholder="Enter your scientific research question..."
              value={query}
              onChange={(e) => setQuery(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleQuery()}
              className="flex-1"
            />
            <Button onClick={handleQuery} disabled={loading || !query.trim()}>
              {loading ? (
                <Loader2 className="w-4 h-4 animate-spin" />
              ) : (
                <Search className="w-4 h-4" />
              )}
            </Button>
          </div>
        </CardContent>
      </Card>

      {/* Query Response */}
      {response && (
        <Card>
          <CardHeader>
            <CardTitle className="flex items-center justify-between">
              <span>Response</span>
              <div className="flex items-center gap-2">
                <Badge variant="outline">{response.query_type}</Badge>
                <Badge 
                  className={`text-white ${formatConfidenceScore(response.confidence_score).color}`}
                >
                  {formatConfidenceScore(response.confidence_score).text} Confidence
                </Badge>
              </div>
            </CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <div className="bg-gray-50 p-4 rounded-lg">
              <p className="whitespace-pre-wrap">{response.response}</p>
            </div>
            
            <div className="grid grid-cols-2 md:grid-cols-4 gap-4 text-sm">
              <div>
                <span className="font-medium">Sources Used:</span> {response.context_chunks_used}
              </div>
              <div>
                <span className="font-medium">Total Found:</span> {response.total_results_found}
              </div>
              <div>
                <span className="font-medium">Processing Time:</span> {response.processing_time.toFixed(2)}s
              </div>
              <div>
                <span className="font-medium">Model:</span> {response.model_used}
              </div>
            </div>

            {/* Sources */}
            {response.sources && response.sources.length > 0 && (
              <div>
                <h4 className="font-medium mb-2">Sources:</h4>
                <div className="space-y-2">
                  {response.sources.slice(0, 5).map((source, index) => (
                    <div key={index} className="border rounded p-3 text-sm">
                      <div className="flex justify-between items-start mb-2">
                        <Badge variant="outline">{source.section}</Badge>
                        <div className="flex items-center gap-2">
                          <span className="text-xs text-gray-500">
                            Relevance: {(source.relevance_score * 100).toFixed(1)}%
                          </span>
                          {source.cited_in_response && (
                            <Badge variant="default" className="text-xs">Cited</Badge>
                          )}
                        </div>
                      </div>
                      <p className="text-gray-700">{source.text_preview}</p>
                    </div>
                  ))}
                </div>
              </div>
            )}
          </CardContent>
        </Card>
      )}

      {/* Example Queries */}
      <Card>
        <CardHeader>
          <CardTitle>Example Queries</CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
            {[
              "What are the latest developments in transformer architectures?",
              "How do neural networks learn representations?",
              "What are the applications of reinforcement learning?",
              "Compare different optimization algorithms for deep learning",
              "What are the challenges in natural language processing?",
              "How does attention mechanism work in neural networks?"
            ].map((exampleQuery, index) => (
              <Button
                key={index}
                variant="outline"
                size="sm"
                onClick={() => setQuery(exampleQuery)}
                className="text-left justify-start h-auto p-2 whitespace-normal"
              >
                {exampleQuery}
              </Button>
            ))}
          </div>
        </CardContent>
      </Card>
    </div>
  );
};

export default ScientificRAG;