version: '3.8'

# AI Scholar Production Docker Compose
# Optimized for Ubuntu 24.04.2 LTS and scholar.cmejo.com
# Includes all services: Frontend, Backend, Databases, Monitoring, SSL

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-bookworm
    container_name: ai-scholar-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ai_scholar_db}
      POSTGRES_USER: ${POSTGRES_USER:-ai_scholar_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    networks:
      - ai-scholar-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ai_scholar_user} -d ${POSTGRES_DB:-ai_scholar_db}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Redis Cache
  redis:
    image: redis:7-bookworm
    container_name: ai-scholar-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD} --maxmemory 512mb --maxmemory-policy allkeys-lru --save 900 1 --save 300 10
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    networks:
      - ai-scholar-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Vector Database (ChromaDB)
  chromadb:
    image: chromadb/chroma:0.4.18
    container_name: ai-scholar-chromadb
    restart: unless-stopped
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "${CHROMA_PORT:-8080}:8000"
    networks:
      - ai-scholar-network
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Ollama for Local LLM Inference
  ollama:
    image: ollama/ollama:latest
    container_name: ai-scholar-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
      - ./scripts/ollama-init.sh:/ollama-init.sh:ro
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    networks:
      - ai-scholar-network
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0:11434
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    # Uncomment if you have NVIDIA GPU support
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all

  # Backend API
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: ai-scholar-backend:latest
    container_name: ai-scholar-backend
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-ai_scholar_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-ai_scholar_db}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - VECTOR_DB_URL=http://chromadb:8000
      - OLLAMA_URL=http://ollama:11434
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ENVIRONMENT=production
      - DEBUG=False
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - HOST=0.0.0.0
      - PORT=8000
      - CORS_ORIGINS=${CORS_ORIGINS:-https://yourdomain.com}
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-100}
      - ENABLE_MONITORING=True
      - PROMETHEUS_METRICS_ENABLED=True
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./backups:/app/backups
      - chroma_data:/app/chroma_db
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    networks:
      - ai-scholar-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      chromadb:
        condition: service_healthy
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Frontend Application
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
      args:
        - BUILDKIT_INLINE_CACHE=1
        - VITE_API_URL=${VITE_API_URL:-https://yourdomain.com/api}
        - VITE_WS_URL=${VITE_WS_URL:-wss://yourdomain.com/ws}
    image: ai-scholar-frontend:latest
    container_name: ai-scholar-frontend
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-3000}:3005"
    networks:
      - ai-scholar-network
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Nginx Reverse Proxy with SSL
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    image: ai-scholar-nginx:latest
    container_name: ai-scholar-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/sites-available:/etc/nginx/sites-available:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
      - certbot_data:/var/www/certbot
      - certbot_conf:/etc/letsencrypt
    networks:
      - ai-scholar-network
    depends_on:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # SSL Certificate Management
  certbot:
    image: certbot/certbot:latest
    container_name: ai-scholar-certbot
    volumes:
      - certbot_data:/var/www/certbot
      - certbot_conf:/etc/letsencrypt
    networks:
      - ai-scholar-network
    profiles:
      - ssl
    command: certonly --webroot --webroot-path=/var/www/certbot --email ${SSL_EMAIL:-admin@scholar.cmejo.com} --agree-tos --no-eff-email -d ${DOMAIN_NAME:-scholar.cmejo.com} -d www.${DOMAIN_NAME:-scholar.cmejo.com}

  # Elasticsearch for Advanced Search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: ai-scholar-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    networks:
      - ai-scholar-network
    profiles:
      - full-stack
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: ai-scholar-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - ai-scholar-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:10.2.0
    container_name: ai-scholar-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://${DOMAIN_NAME}/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    networks:
      - ai-scholar-network
    profiles:
      - monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Worker for Background Tasks
  worker:
    build:
      context: .
      dockerfile: Dockerfile.backend
    image: ai-scholar-backend:latest
    container_name: ai-scholar-worker
    restart: unless-stopped
    command: celery -A app.celery worker --loglevel=info --concurrency=4
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-ai_scholar_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-ai_scholar_db}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - VECTOR_DB_URL=http://chromadb:8000
      - OLLAMA_URL=http://ollama:11434
      - SECRET_KEY=${SECRET_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY}
      - ENVIRONMENT=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - chroma_data:/app/chroma_db
    networks:
      - ai-scholar-network
    depends_on:
      - postgres
      - redis
      - ollama
    profiles:
      - workers
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Scheduler for Periodic Tasks
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile.backend
    image: ai-scholar-backend:latest
    container_name: ai-scholar-scheduler
    restart: unless-stopped
    command: celery -A app.celery beat --loglevel=info
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-ai_scholar_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-ai_scholar_db}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
      - ENVIRONMENT=production
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./logs:/app/logs
    networks:
      - ai-scholar-network
    depends_on:
      - postgres
      - redis
    profiles:
      - workers
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Backup Service
  backup:
    build:
      context: .
      dockerfile: Dockerfile.backup
    container_name: ai-scholar-backup
    restart: unless-stopped
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB:-ai_scholar_db}
      - POSTGRES_USER=${POSTGRES_USER:-ai_scholar_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
      - S3_BUCKET=${S3_BACKUP_BUCKET}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    volumes:
      - ./backups:/backups
      - ./uploads:/app/uploads:ro
      - postgres_data:/var/lib/postgresql/data:ro
      - chroma_data:/chroma:ro
    networks:
      - ai-scholar-network
    depends_on:
      - postgres
    profiles:
      - backup
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Node Exporter for System Metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: ai-scholar-node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    networks:
      - ai-scholar-network
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # Redis Exporter for Redis Metrics
  redis-exporter:
    image: oliver006/redis_exporter:v1.55.0
    container_name: ai-scholar-redis-exporter
    restart: unless-stopped
    environment:
      - REDIS_ADDR=redis://redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    ports:
      - "9121:9121"
    networks:
      - ai-scholar-network
    depends_on:
      - redis
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M

  # Postgres Exporter for Database Metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: ai-scholar-postgres-exporter
    restart: unless-stopped
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER:-ai_scholar_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-ai_scholar_db}?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - ai-scholar-network
    depends_on:
      - postgres
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M

networks:
  ai-scholar-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
    driver_opts:
      com.docker.network.bridge.name: ai-scholar-br0

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/redis
  chroma_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/chroma
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/ollama
  elasticsearch_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/elasticsearch
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/grafana
  certbot_data:
    driver: local
  certbot_conf:
    driver: local